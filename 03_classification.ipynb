{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. 분별(Classification) 문제: 이탈 고객 감지하기\n",
    "\n",
    "## 비즈니스 상황\n",
    "\n",
    "* 신규 고객 획득 비용은 기존 고객 유지 비용보다 5-25배 이상 높음(<a href=\"https://hbr.org/2014/10/the-value-of-keeping-the-right-customers\" target=\"_blank\">HBR</a>).\n",
    "* 또한 충성도 높은 고객 기반은 upselling 또는 VOC 수집 등이 가능하여 1차 비용 절감 이상의 전략적 가치를 지닌, 지속 가능한 성장의 밑바탕 자산임.\n",
    "* 고객 행동의 예후를 바탕으로 이탈 가능성을 미리 파악할 경우, 타겟팅된 마케팅 전략으로 이탈을 일부 방어하여 유지율을 높일 수 있음.\n",
    "\n",
    "## 분석 제목\n",
    "\n",
    "* _A(어떤 데이터로)_: **가입 고객의 프로필 데이터로** \n",
    "* _B(어떤 분석 컨셉으로)_: **해지 여부를 사전에 예측하여**\n",
    "* _C(어떤 결론을 내어)_: **위험 고객에 선제적 프로모션으로** \n",
    "* _D(어떤 가치를 더할지)_: **고객 이탈을 방지함**\n",
    "\n",
    "## 데이터 준비\n",
    "\n",
    "* 나이 (`age`): 고객의 나이\n",
    "* 성별 (`gender`): 고객 성별 (1: 남성, 0: 여성)\n",
    "* 가입 유형 (`subscription_type`): 가입 유형 (1: 기본, 2: 프리미엄, 3: 가족, 4: 맞춤)\n",
    "* 평균 월간 지출 (`average_spend`): 평균 월간 지출액\n",
    "* 가입 기간 (`duration`): 가입 기간 (주 수로 표현)\n",
    "* 이벤트 이용 여부 (`promotion`): 프로모션 이벤트 이용 여부 (1: 자주 이용, 0: 거의/전혀 이용하지 않음)\n",
    "* 피드백 응답 (`feedback_response`): 고객의 피드백 상태 (0: 응답하지 않음, 1: 부정적 응답, 2: 긍정적 응답)\n",
    "* 앱에서의 활동 레벨 (`app_activity`): 앱에서의 평균 월간 로그인 빈도\n",
    "* 고객 불만 (`complaints`): 불만이 있었는지 (1: 있음, 0: 없음)\n",
    "* 할인 민감도 (`discount_sensitivity`): 할인에 대한 민감도 (0-1 사이의 소수점; 높을수록 민감)\n",
    "* 결제 방법 (`payment_method`): 선호 결제 방법 (1: 신용카드, 2: 직불카드, 3: 기타)\n",
    "* 이탈 여부 (`churn`): 멤버십 해지 여부 (0: 해지하지 않음, 1: 해지함)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.1 [TASK] pandas 패키지를 불러오고 \"churn_data.csv\" 파일을 열어 data 변수로 저장합니다\n",
    "# 그리고 ChatGPT에게 질문할 수 있도록 준비해둡니다\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.2 범주형 데이터를 수치형에서 변환\n",
    "category_variables = [\"gender\", \"subscription_type\", \"promotion\", \"feedback_response\", \"complaints\", \"payment_method\"]\n",
    "data[category_variables] = data[category_variables].astype(\"string\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 탐색 분석(EDA)\n",
    "\n",
    "여기에서는 자동 EDA 툴을 사용하여 데이터를 탐색함."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.3 데이터 레포트\n",
    "import warnings\n",
    "import sweetviz as sv\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "my_report = sv.analyze(data)\n",
    "my_report.show_notebook()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델링을 위한 데이터 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.4 범주형 데이터 처리하기 (dummy 변수)\n",
    "data2 = pd.get_dummies(data, columns=category_variables, drop_first=True)\n",
    "data2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.5 [TASK] 모델링을 위해 data2에서 X와 y(\"churn\")를 분리합니다\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.6 [TASK] 변수 스케일링\n",
    "# 아래와 같이 age 변수에 대해 스케일링을 합니다\n",
    "# Z-Score = (값 - 평균) / 표준편차\n",
    "age_values = data2[\"age\"]\n",
    "age_mean = age_values.mean()\n",
    "age_stdev = age_values.std()\n",
    "age_scaled = (____ - ____) / ____\n",
    "age_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.7 [TASK] 변수 스케일링\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "X_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.8 중요! [TASK] X_scaled와 y를 train과 test로 나눕니다\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델링"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "참고: [로지스틱 회귀 시각화](https://mlu-explain.github.io/logistic-regression/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.9 [TASK] X_train, X_test, y_train, y_test이 있을 때 로지스틱 회귀 모델로 예측한 후 정확도를 출력합니다\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "참고: [구글 신경망 플레이그라운드](https://playground.tensorflow.org/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.10 [TASK] X_train, X_test, y_train, y_test이 있을 때 신경망 모델로 예측한 후 정확도를 출력합니다 (MLPClassifier 이용)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "참고: [랜덤 포레스트 시각화](http://www.r2d3.us/visual-intro-to-machine-learning-part-1/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.11 [TASK] X_train, X_test, y_train, y_test이 있을 때 랜덤포레스트 모델로 예측한 후 정확도를 출력합니다\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 결과 해석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.12 [TASK] random_forest_model 예측 값의 혼동 행렬(confusion matrix)를 plot으로 출력한 후 정확도, 정밀도, 회수율을 계산합니다\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.13 [TASK] random_forest_model 예측의 요인별 중요도를 plot으로 출력합니다\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 첨부. 완성된 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score\n",
    "\n",
    "data = pd.read_csv(\"churn_data.csv\")\n",
    "category_variables = [\"gender\", \"subscription_type\", \"promotion\",\n",
    "                      \"feedback_response\", \"complaints\", \"payment_method\"]\n",
    "data[category_variables] = data[category_variables].astype(\"string\")\n",
    "data2 = pd.get_dummies(data, columns=category_variables, drop_first=True)\n",
    "\n",
    "X = data2.drop('churn', axis=1)\n",
    "y = data2['churn']\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "X_scaled_train, X_scaled_test, y_train, y_test = train_test_split(\n",
    "    X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "logistic_model = LogisticRegression()\n",
    "logistic_model.fit(X_scaled_train, y_train)\n",
    "logistic_y_pred = logistic_model.predict(X_scaled_test)\n",
    "accuracy_score(y_test, logistic_y_pred)\n",
    "\n",
    "rf_model = RandomForestClassifier()\n",
    "rf_model.fit(X_scaled_train, y_train)\n",
    "rf_y_pred = rf_model.predict(X_scaled_test)\n",
    "accuracy_score(y_test, rf_y_pred)\n",
    "\n",
    "nn_model = MLPClassifier()\n",
    "nn_model.fit(X_scaled_train, y_train)\n",
    "nn_y_pred = nn_model.predict(X_scaled_test)\n",
    "accuracy_score(y_test, nn_y_pred)\n",
    "\n",
    "confusion_matrix = confusion_matrix(y_test, rf_y_pred)\n",
    "sns.heatmap(confusion_matrix, annot=True, cmap=\"Blues\", fmt=\"d\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()\n",
    "accuracy_score(y_test, rf_y_pred), precision_score(y_test, rf_y_pred), recall_score(y_test, rf_y_pred)\n",
    "\n",
    "importances = rf_model.feature_importances_\n",
    "sns.barplot(x=importances, y=X.columns)\n",
    "plt.xlabel(\"Importance\")\n",
    "plt.ylabel(\"Features\")\n",
    "plt.title(\"Feature Importances\")\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
